{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11529268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 30)\n",
      "(3, 94)\n",
      "(9, 8)\n",
      "(9, 100)\n",
      "(9, 155)\n",
      "(9, 187)\n",
      "(9, 188)\n",
      "(20, 49)\n",
      "(20, 51)\n",
      "(20, 90)\n",
      "[[30, 94], [8, 100, 155, 187, 188], [49, 51, 90]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27668/1525151230.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mATL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27668/1525151230.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, train, Nclasses, Nlayer, Pmax)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mfm_indicies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_out_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_featuremaps_idicies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfm_indicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27668/1525151230.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, m, n, layers, idx)\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minserting_after\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m                 new_node = graph.call_function(torch.index_select,\n\u001b[1;32m--> 125\u001b[1;33m                                               args=(final_nodes[i], 1, last_node))\n\u001b[0m\u001b[0;32m    126\u001b[0m                 \u001b[0mlast_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx as fx\n",
    "import numpy as np\n",
    "from torch.fx import symbolic_trace\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "class ATL(nn.Module):\n",
    "    def __init__(self, train, Nclasses, Nlayer=3, Pmax=0.4):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        layers = self.get_layers(train)\n",
    "        \n",
    "        fm_indicies, resnet_out_size = self.get_featuremaps_idicies(train,layers)        \n",
    "        self.resnet = self._transform(self.resnet, Nlayer, layers, fm_indicies)\n",
    "        \n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fcl = nn.Linear(resnet_out_size, Nclasses)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "        \n",
    "    def get_layers(self, train):\n",
    "        # Musi zwracać coś w tym stylu, tj iterowalny obiekt z N conv layers\n",
    "        \n",
    "        return [3,9,20] # najlepiej indeksy warstw konwolucyjnych \n",
    "    \n",
    "    def get_featuremaps_idicies(self, train, layers, N_feature  = 3):\n",
    "        \n",
    "        # obecnie bez pilnowania finalnej liczyby wybranych feature map\n",
    "        # bez pilnownaia zeby z każdej klasy było n_feature map \n",
    "        # bez obliczania progu p value dla każdej klasy w warstwie (ustalona sztywna wartość 0.05)\n",
    "        \n",
    "        images, labels = trainset \n",
    "        labels_set = set(np.asarray(labels))\n",
    "                \n",
    "        conv_layers,model_weights = self.get_resnet_conv_layers()\n",
    "    \n",
    "        choose_fm = []\n",
    "        choose_fm_output_len=0\n",
    "        # iteruje po warstwach konwolucyjnuch \n",
    "        for conv_ind in layers:\n",
    "            choose_fm_curent_conv_layer = []\n",
    "            \n",
    "            # iteruje po mapach             \n",
    "            for fm_ind in range(len(model_weights[conv_ind])):                \n",
    "                LAV_vec = []\n",
    "                \n",
    "                \n",
    "                for image in images:\n",
    "                    out_fm = self.get_feature_map_outputs(image)\n",
    "                    \n",
    "                    LAV_vec.append(self.LAV(out_fm[conv_ind][fm_ind]))\n",
    "                 \n",
    "                for _class in labels_set:\n",
    "                    LAV_vec_curent_class = []\n",
    "                    LAV_vec_other_class = []\n",
    "                    for i,fm in enumerate(LAV_vec):\n",
    "                        if labels[i]==_class:\n",
    "                            LAV_vec_curent_class.append(fm)\n",
    "                        else:     \n",
    "                            LAV_vec_other_class.append(fm)\n",
    "                    \n",
    "                    # zwraca nan przy LAV_vec_current_class długości 1 !!\n",
    "                    t_stat, p = ttest_ind(LAV_vec_curent_class, LAV_vec_other_class)\n",
    "                    #print(\"t_stat, p\", t_stat, p )\n",
    "                    \n",
    "                    # TODO pl = p_max * Rl/Rmax\n",
    "                    p_treshold = 0.05 # testowo\n",
    "                    \n",
    "                    if p < p_treshold:\n",
    "                        choose_fm_curent_conv_layer.append(fm_ind)\n",
    "                        \n",
    "                        map_dim = out_fm[conv_ind][fm_ind]\n",
    "                        #print(map_dim)\n",
    "                        \n",
    "                        choose_fm_output_len+= map_dim[0].size()[0] **2\n",
    "                        \n",
    "                        print((conv_ind,fm_ind))\n",
    "            choose_fm.append(choose_fm_curent_conv_layer)\n",
    "        \n",
    "        print (choose_fm)\n",
    "        \n",
    "        # Musi zwracać obiekt który ma N iterowalnych rzeczy, z których każda ma ileś indeksów feature map. \n",
    "        # W sumie ilość indeksów musi być równa ilości klas * Nfeature z 2.3 w artykule\n",
    "        #return [[1],[1]], 1568\n",
    "        \n",
    "        return choose_fm,choose_fm_output_len  # na razie zwraca coś takiego: [[30, 94], [8, 100, 155, 187, 188], [49, 51, 90]]\n",
    "        \n",
    "\n",
    "    \n",
    "    def LAV(self,featureMap):\n",
    "        return featureMap.max().detach().numpy().item(0)\n",
    "    \n",
    "    def _transform(self, m: torch.nn.Module, n, layers, idx) -> torch.nn.Module:\n",
    "        gm : torch.fx.GraphModule = torch.fx.symbolic_trace(m)\n",
    "        graph=gm.graph\n",
    "        final_nodes=[]\n",
    "        last_node=None\n",
    "\n",
    "        for node in graph.nodes:\n",
    "            if node.name in layers:\n",
    "                final_nodes.append(node)\n",
    "            if not last_node and len(final_nodes)==n:\n",
    "                last_node = node\n",
    "            if node.name == 'output':\n",
    "                out_node = node\n",
    "\n",
    "        i=0\n",
    "        nodes_to_output=[]\n",
    "        for i in range(n):\n",
    "            with graph.inserting_after(last_node):\n",
    "            # Insert a new `call_function` node calling `torch.relu`\n",
    "                new_node = graph.call_function(torch.tensor,\n",
    "                                               args=(idx[i],),\n",
    "                                              kwargs={\"dtype\":torch.int32})\n",
    "                last_node = new_node\n",
    "\n",
    "            with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.index_select,\n",
    "                                              args=(final_nodes[i], 1, last_node))\n",
    "                last_node = new_node\n",
    "\n",
    "            with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.flatten,\n",
    "                                              args=(last_node,1))\n",
    "                nodes_to_output.append(new_node)\n",
    "                last_node = new_node\n",
    "        with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.cat,\n",
    "                                              args=(nodes_to_output,1))\n",
    "        out_node.args=(new_node,)\n",
    "        graph.eliminate_dead_code()\n",
    "        graph.lint() \n",
    "        gm.recompile()\n",
    "\n",
    "        return gm\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.fcl(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def get_resnet_conv_layers(self):\n",
    "        model = self.resnet\n",
    "        # we will save the conv layer weights in this list\n",
    "        model_weights =[]\n",
    "\n",
    "        #we will save the 49 conv layers in this list\n",
    "        conv_layers = []\n",
    "\n",
    "        # get all the model children as list\n",
    "        model_children = list(model.children())\n",
    "\n",
    "        #counter to keep count of the conv layers\n",
    "        counter = 0\n",
    "        #append all the conv layers and their respective wights to the list\n",
    "\n",
    "        for i in range(len(model_children)):\n",
    "\n",
    "            if type(model_children[i]) == nn.Conv2d:\n",
    "                counter+=1\n",
    "                model_weights.append(model_children[i].weight)\n",
    "                conv_layers.append(model_children[i])\n",
    "\n",
    "            elif type(model_children[i]) == nn.Sequential:\n",
    "                for j in range(len(model_children[i])):\n",
    "                    for child in model_children[i][j].children():\n",
    "                        if type(child) == nn.Conv2d:\n",
    "                            counter+=1\n",
    "                            model_weights.append(child.weight)\n",
    "                            conv_layers.append(child)\n",
    "\n",
    "        #print(f\"Total convolution layers: {counter}\")\n",
    "        #print(\"conv_layers\")\n",
    "        return (conv_layers,model_weights)\n",
    "    \n",
    "    def get_feature_map_outputs(self,image):\n",
    "        conv_layers, _ = self.get_resnet_conv_layers()\n",
    "        outputs = []\n",
    "        names = []\n",
    "\n",
    "        for layer in conv_layers[0:]:\n",
    "            image = layer(image)\n",
    "            outputs.append(image)\n",
    "            names.append(str(layer))\n",
    "            \n",
    "        #print(len(outputs))\n",
    "\n",
    "        # print feature_maps\n",
    "        #for feature_map in outputs:\n",
    "            #print(feature_map.shape)\n",
    "            \n",
    "        return outputs;   \n",
    "\n",
    "\n",
    "# testy\n",
    "transform = transforms.Compose([            #[1]\n",
    "             transforms.Resize(256),                    #[2]\n",
    "             transforms.CenterCrop(224),                #[3]\n",
    "             transforms.ToTensor(),                     #[4]\n",
    "             transforms.Normalize(                      #[5]\n",
    "             mean=[0.485, 0.456, 0.406],                #[6]\n",
    "             std=[0.229, 0.224, 0.225]                  #[7]\n",
    "             )])\n",
    "\n",
    "\n",
    "#img = Image.open(\"dog.jpg\")\n",
    "#img = Image.open('img/cat.jpg')\n",
    "#img_t = transform(img)\n",
    "#batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR10 \n",
    "import torchvision\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "trainset = images, labels\n",
    "#print(trainset)\n",
    "\n",
    "\n",
    "m = ATL(trainset, 5, 2)\n",
    "m.eval()\n",
    "\n",
    "# out=m(batch_t)\n",
    "# out.size()\n",
    "\n",
    "#print(symbolic_trace(m.resnet).code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
