{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11529268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "(3, 3)\n",
      "256\n",
      "(3, 5)\n",
      "256\n",
      "(3, 5)\n",
      "256\n",
      "(3, 6)\n",
      "256\n",
      "(3, 7)\n",
      "256\n",
      "(3, 8)\n",
      "256\n",
      "(3, 8)\n",
      "256\n",
      "(3, 9)\n",
      "256\n",
      "(3, 10)\n",
      "256\n",
      "(3, 10)\n",
      "256\n",
      "(3, 12)\n",
      "256\n",
      "(3, 17)\n",
      "256\n",
      "(3, 18)\n",
      "256\n",
      "(3, 24)\n",
      "256\n",
      "(3, 29)\n",
      "256\n",
      "(3, 34)\n",
      "256\n",
      "(3, 35)\n",
      "256\n",
      "(3, 43)\n",
      "256\n",
      "(3, 43)\n",
      "256\n",
      "(3, 45)\n",
      "256\n",
      "(3, 46)\n",
      "256\n",
      "(3, 49)\n",
      "256\n",
      "(3, 51)\n",
      "256\n",
      "(3, 52)\n",
      "256\n",
      "(3, 54)\n",
      "256\n",
      "(3, 55)\n",
      "256\n",
      "(3, 59)\n",
      "256\n",
      "(3, 59)\n",
      "256\n",
      "(3, 60)\n",
      "256\n",
      "(3, 63)\n",
      "256\n",
      "(3, 64)\n",
      "256\n",
      "(3, 67)\n",
      "256\n",
      "(3, 70)\n",
      "256\n",
      "(3, 73)\n",
      "256\n",
      "(3, 73)\n",
      "256\n",
      "(3, 74)\n",
      "256\n",
      "(3, 83)\n",
      "256\n",
      "(3, 87)\n",
      "256\n",
      "(3, 87)\n",
      "256\n",
      "(3, 89)\n",
      "256\n",
      "(3, 92)\n",
      "256\n",
      "(3, 93)\n",
      "256\n",
      "(3, 93)\n",
      "256\n",
      "(3, 94)\n",
      "256\n",
      "(3, 94)\n",
      "256\n",
      "(3, 98)\n",
      "256\n",
      "(3, 98)\n",
      "256\n",
      "(3, 100)\n",
      "256\n",
      "(3, 101)\n",
      "256\n",
      "(3, 102)\n",
      "256\n",
      "(3, 105)\n",
      "256\n",
      "(3, 107)\n",
      "256\n",
      "(3, 109)\n",
      "256\n",
      "(3, 109)\n",
      "256\n",
      "(3, 110)\n",
      "256\n",
      "(3, 110)\n",
      "256\n",
      "(3, 118)\n",
      "256\n",
      "(3, 120)\n",
      "256\n",
      "(3, 123)\n",
      "256\n",
      "(3, 124)\n",
      "256\n",
      "(3, 125)\n",
      "256\n",
      "(3, 125)\n",
      "256\n",
      "(3, 126)\n",
      "256\n",
      "(3, 128)\n",
      "256\n",
      "(3, 129)\n",
      "256\n",
      "(3, 129)\n",
      "256\n",
      "(3, 130)\n",
      "256\n",
      "(3, 131)\n",
      "256\n",
      "(3, 132)\n",
      "256\n",
      "(3, 134)\n",
      "256\n",
      "(3, 136)\n",
      "256\n",
      "(3, 139)\n",
      "256\n",
      "(3, 141)\n",
      "256\n",
      "(3, 145)\n",
      "256\n",
      "(3, 145)\n",
      "256\n",
      "(3, 147)\n",
      "256\n",
      "(3, 148)\n",
      "256\n",
      "(3, 152)\n",
      "256\n",
      "(3, 155)\n",
      "256\n",
      "(3, 155)\n",
      "256\n",
      "(3, 157)\n",
      "256\n",
      "(3, 164)\n",
      "256\n",
      "(3, 165)\n",
      "256\n",
      "(3, 167)\n",
      "256\n",
      "(3, 167)\n",
      "256\n",
      "(3, 168)\n",
      "256\n",
      "(3, 173)\n",
      "256\n",
      "(3, 174)\n",
      "256\n",
      "(3, 175)\n",
      "256\n",
      "(3, 175)\n",
      "256\n",
      "(3, 177)\n",
      "256\n",
      "(3, 179)\n",
      "256\n",
      "(3, 179)\n",
      "256\n",
      "(3, 180)\n",
      "256\n",
      "(3, 181)\n",
      "256\n",
      "(3, 182)\n",
      "256\n",
      "(3, 186)\n",
      "256\n",
      "(3, 187)\n",
      "256\n",
      "(3, 190)\n",
      "256\n",
      "(3, 190)\n",
      "256\n",
      "(3, 191)\n",
      "256\n",
      "(3, 192)\n",
      "256\n",
      "(3, 194)\n",
      "256\n",
      "(3, 198)\n",
      "256\n",
      "(3, 198)\n",
      "256\n",
      "(3, 201)\n",
      "256\n",
      "(3, 203)\n",
      "256\n",
      "(3, 204)\n",
      "256\n",
      "(3, 208)\n",
      "256\n",
      "(3, 209)\n",
      "256\n",
      "(3, 210)\n",
      "256\n",
      "(3, 211)\n",
      "256\n",
      "(3, 214)\n",
      "256\n",
      "(3, 215)\n",
      "256\n",
      "(3, 216)\n",
      "256\n",
      "(3, 219)\n",
      "256\n",
      "(3, 221)\n",
      "256\n",
      "(3, 221)\n",
      "256\n",
      "(3, 222)\n",
      "256\n",
      "(3, 227)\n",
      "256\n",
      "(3, 228)\n",
      "256\n",
      "(3, 229)\n",
      "256\n",
      "(3, 229)\n",
      "256\n",
      "(3, 231)\n",
      "256\n",
      "(3, 231)\n",
      "256\n",
      "(3, 232)\n",
      "256\n",
      "(3, 237)\n",
      "256\n",
      "(3, 245)\n",
      "256\n",
      "(3, 251)\n",
      "256\n",
      "(3, 251)\n",
      "256\n",
      "(3, 255)\n",
      "256\n",
      "(9, 5)\n",
      "256\n",
      "(9, 6)\n",
      "256\n",
      "(9, 8)\n",
      "256\n",
      "(9, 8)\n",
      "256\n",
      "(9, 10)\n",
      "256\n",
      "(9, 11)\n",
      "256\n",
      "(9, 17)\n",
      "256\n",
      "(9, 18)\n",
      "256\n",
      "(9, 24)\n",
      "256\n",
      "(9, 29)\n",
      "256\n",
      "(9, 30)\n",
      "256\n",
      "(9, 32)\n",
      "256\n",
      "(9, 33)\n",
      "256\n",
      "(9, 40)\n",
      "256\n",
      "(9, 50)\n",
      "256\n",
      "(9, 57)\n",
      "256\n",
      "(9, 57)\n",
      "256\n",
      "(9, 60)\n",
      "256\n",
      "(9, 62)\n",
      "256\n",
      "(9, 65)\n",
      "256\n",
      "(9, 70)\n",
      "256\n",
      "(9, 72)\n",
      "256\n",
      "(9, 86)\n",
      "256\n",
      "(9, 88)\n",
      "256\n",
      "(9, 89)\n",
      "256\n",
      "(9, 90)\n",
      "256\n",
      "(9, 92)\n",
      "256\n",
      "(9, 97)\n",
      "256\n",
      "(9, 102)\n",
      "256\n",
      "(9, 104)\n",
      "256\n",
      "(9, 121)\n",
      "256\n",
      "(9, 122)\n",
      "256\n",
      "(9, 130)\n",
      "256\n",
      "(9, 135)\n",
      "256\n",
      "(9, 138)\n",
      "256\n",
      "(9, 140)\n",
      "256\n",
      "(9, 141)\n",
      "256\n",
      "(9, 151)\n",
      "256\n",
      "(9, 153)\n",
      "256\n",
      "(9, 160)\n",
      "256\n",
      "(9, 162)\n",
      "256\n",
      "(9, 166)\n",
      "256\n",
      "(9, 168)\n",
      "256\n",
      "(9, 170)\n",
      "256\n",
      "(9, 174)\n",
      "256\n",
      "(9, 175)\n",
      "256\n",
      "(9, 184)\n",
      "256\n",
      "(9, 186)\n",
      "256\n",
      "(9, 187)\n",
      "256\n",
      "(9, 188)\n",
      "256\n",
      "(9, 195)\n",
      "256\n",
      "(9, 200)\n",
      "256\n",
      "(9, 202)\n",
      "256\n",
      "(9, 210)\n",
      "256\n",
      "(9, 212)\n",
      "256\n",
      "(9, 216)\n",
      "256\n",
      "(9, 217)\n",
      "256\n",
      "(9, 219)\n",
      "256\n",
      "(9, 232)\n",
      "256\n",
      "(9, 238)\n",
      "256\n",
      "(9, 239)\n",
      "256\n",
      "(9, 242)\n",
      "256\n",
      "(9, 253)\n",
      "64\n",
      "(20, 3)\n",
      "64\n",
      "(20, 4)\n",
      "64\n",
      "(20, 5)\n",
      "64\n",
      "(20, 6)\n",
      "64\n",
      "(20, 12)\n",
      "64\n",
      "(20, 13)\n",
      "64\n",
      "(20, 16)\n",
      "64\n",
      "(20, 18)\n",
      "64\n",
      "(20, 21)\n",
      "64\n",
      "(20, 22)\n",
      "64\n",
      "(20, 23)\n",
      "64\n",
      "(20, 24)\n",
      "64\n",
      "(20, 25)\n",
      "64\n",
      "(20, 26)\n",
      "64\n",
      "(20, 28)\n",
      "64\n",
      "(20, 31)\n",
      "64\n",
      "(20, 32)\n",
      "64\n",
      "(20, 34)\n",
      "64\n",
      "(20, 35)\n",
      "64\n",
      "(20, 36)\n",
      "64\n",
      "(20, 37)\n",
      "64\n",
      "(20, 38)\n",
      "64\n",
      "(20, 39)\n",
      "64\n",
      "(20, 41)\n",
      "64\n",
      "(20, 42)\n",
      "64\n",
      "(20, 44)\n",
      "64\n",
      "(20, 47)\n",
      "64\n",
      "(20, 48)\n",
      "64\n",
      "(20, 51)\n",
      "64\n",
      "(20, 52)\n",
      "64\n",
      "(20, 54)\n",
      "64\n",
      "(20, 55)\n",
      "64\n",
      "(20, 58)\n",
      "64\n",
      "(20, 60)\n",
      "64\n",
      "(20, 66)\n",
      "64\n",
      "(20, 68)\n",
      "64\n",
      "(20, 71)\n",
      "64\n",
      "(20, 73)\n",
      "64\n",
      "(20, 74)\n",
      "64\n",
      "(20, 75)\n",
      "64\n",
      "(20, 78)\n",
      "64\n",
      "(20, 79)\n",
      "64\n",
      "(20, 80)\n",
      "64\n",
      "(20, 82)\n",
      "64\n",
      "(20, 83)\n",
      "64\n",
      "(20, 85)\n",
      "64\n",
      "(20, 86)\n",
      "64\n",
      "(20, 89)\n",
      "64\n",
      "(20, 94)\n",
      "64\n",
      "(20, 95)\n",
      "64\n",
      "(20, 96)\n",
      "64\n",
      "(20, 98)\n",
      "64\n",
      "(20, 99)\n",
      "64\n",
      "(20, 101)\n",
      "64\n",
      "(20, 102)\n",
      "64\n",
      "(20, 104)\n",
      "64\n",
      "(20, 112)\n",
      "64\n",
      "(20, 114)\n",
      "64\n",
      "(20, 118)\n",
      "64\n",
      "(20, 119)\n",
      "64\n",
      "(20, 121)\n",
      "64\n",
      "(20, 126)\n",
      "64\n",
      "(20, 127)\n",
      "[[3, 5, 5, 6, 7, 8, 8, 9, 10, 10, 12, 17, 18, 24, 29, 34, 35, 43, 43, 45, 46, 49, 51, 52, 54, 55, 59, 59, 60, 63, 64, 67, 70, 73, 73, 74, 83, 87, 87, 89, 92, 93, 93, 94, 94, 98, 98, 100, 101, 102, 105, 107, 109, 109, 110, 110, 118, 120, 123, 124, 125, 125, 126, 128, 129, 129, 130, 131, 132, 134, 136, 139, 141, 145, 145, 147, 148, 152, 155, 155, 157, 164, 165, 167, 167, 168, 173, 174, 175, 175, 177, 179, 179, 180, 181, 182, 186, 187, 190, 190, 191, 192, 194, 198, 198, 201, 203, 204, 208, 209, 210, 211, 214, 215, 216, 219, 221, 221, 222, 227, 228, 229, 229, 231, 231, 232, 237, 245, 251, 251, 255], [5, 6, 8, 8, 10, 11, 17, 18, 24, 29, 30, 32, 33, 40, 50, 57, 57, 60, 62, 65, 70, 72, 86, 88, 89, 90, 92, 97, 102, 104, 121, 122, 130, 135, 138, 140, 141, 151, 153, 160, 162, 166, 168, 170, 174, 175, 184, 186, 187, 188, 195, 200, 202, 210, 212, 216, 217, 219, 232, 238, 239, 242, 253], [3, 4, 5, 6, 12, 13, 16, 18, 21, 22, 23, 24, 25, 26, 28, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 47, 48, 51, 52, 54, 55, 58, 60, 66, 68, 71, 73, 74, 75, 78, 79, 80, 82, 83, 85, 86, 89, 94, 95, 96, 98, 99, 101, 102, 104, 112, 114, 118, 119, 121, 126, 127]]\n",
      "53696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ATL(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Module(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (fcl): Linear(in_features=53696, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx as fx\n",
    "import numpy as np\n",
    "from torch.fx import symbolic_trace\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from scipy.stats import ttest_ind\n",
    "import torch.optim as optim\n",
    "\n",
    "class ATL(nn.Module):\n",
    "    def __init__(self, train, Nclasses, Nlayer=3, Pmax=0.4):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        layers = self.get_layers(train)\n",
    "        \n",
    "        fm_indicies, resnet_out_size = self.get_featuremaps_idicies(train,layers)        \n",
    "        self.resnet = self._transform(self.resnet, Nlayer, layers, fm_indicies)\n",
    "        \n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fcl = nn.Linear(resnet_out_size, Nclasses)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "        \n",
    "    def get_layers(self, train):\n",
    "        # Musi zwracać coś w tym stylu, tj iterowalny obiekt z N conv layers\n",
    "        \n",
    "        return [3,9,20] # najlepiej indeksy warstw konwolucyjnych \n",
    "    \n",
    "    def get_featuremaps_idicies(self, train, layers, N_feature  = 3):\n",
    "        \n",
    "        # obecnie bez pilnowania finalnej liczyby wybranych feature map\n",
    "        # bez pilnownaia zeby z każdej klasy było n_feature map \n",
    "        # bez obliczania progu p value dla każdej klasy w warstwie (ustalona sztywna wartość 0.05)\n",
    "        \n",
    "        images, labels = trainset \n",
    "        labels_set = set(np.asarray(labels))\n",
    "                \n",
    "        conv_layers,model_weights = self.get_resnet_conv_layers()\n",
    "    \n",
    "        choose_fm = []\n",
    "        choose_fm_output_len=0\n",
    "        # iteruje po warstwach konwolucyjnuch \n",
    "        for conv_ind in layers:\n",
    "            choose_fm_curent_conv_layer = []\n",
    "            \n",
    "            # iteruje po mapach             \n",
    "            for fm_ind in range(len(model_weights[conv_ind])):                \n",
    "                LAV_vec = []\n",
    "                \n",
    "                \n",
    "                for image in images:\n",
    "                    out_fm = self.get_feature_map_outputs(image)\n",
    "                    \n",
    "                    LAV_vec.append(self.LAV(out_fm[conv_ind][fm_ind]))\n",
    "                 \n",
    "                for _class in labels_set:\n",
    "                    LAV_vec_curent_class = []\n",
    "                    LAV_vec_other_class = []\n",
    "                    for i,fm in enumerate(LAV_vec):\n",
    "                        if labels[i]==_class:\n",
    "                            LAV_vec_curent_class.append(fm)\n",
    "                        else:     \n",
    "                            LAV_vec_other_class.append(fm)\n",
    "                    \n",
    "                    # zwraca nan przy LAV_vec_current_class długości 1 !!\n",
    "                    t_stat, p = ttest_ind(LAV_vec_curent_class, LAV_vec_other_class)\n",
    "                    #print(\"t_stat, p\", t_stat, p )\n",
    "                    \n",
    "                    # TODO pl = p_max * Rl/Rmax\n",
    "                    p_treshold = 0.05 # testowo\n",
    "                    \n",
    "                    if p < p_treshold:\n",
    "                        choose_fm_curent_conv_layer.append(fm_ind)\n",
    "                        \n",
    "                        map_dim = out_fm[conv_ind][fm_ind]\n",
    "                        #print(map_dim)\n",
    "                        \n",
    "                        choose_fm_output_len+= map_dim[0].size()[0] **2\n",
    "                        print(map_dim[0].size()[0] **2)\n",
    "                        \n",
    "                        print((conv_ind,fm_ind))\n",
    "            choose_fm.append(choose_fm_curent_conv_layer)\n",
    "        \n",
    "        print (choose_fm)\n",
    "        print (choose_fm_output_len)\n",
    "        \n",
    "        # Musi zwracać obiekt który ma N iterowalnych rzeczy, z których każda ma ileś indeksów feature map. \n",
    "        # W sumie ilość indeksów musi być równa ilości klas * Nfeature z 2.3 w artykule\n",
    "        #return [[1],[1]], 1568\n",
    "        \n",
    "        return choose_fm, choose_fm_output_len  # na razie zwraca coś takiego: [[30, 94], [8, 100, 155, 187, 188], [49, 51, 90]]\n",
    "        \n",
    "\n",
    "    \n",
    "    def LAV(self,featureMap):\n",
    "        return featureMap.max().detach().numpy().item(0)\n",
    "    \n",
    "    def _transform(self, m: torch.nn.Module, n, layers, idx) -> torch.nn.Module:\n",
    "        gm : torch.fx.GraphModule = torch.fx.symbolic_trace(m)\n",
    "        graph=gm.graph\n",
    "        blocks_in_layers = [1,3,4,6,3]\n",
    "        idx_to_layer_name = ['conv1'] + [f\"layer{i}_{j}_conv{k}\" for i in range(1,5) for j in range(blocks_in_layers[i]) for k in range(1,4)]\n",
    "        layer_names = [idx_to_layer_name[idx] for idx in layers]\n",
    "        final_nodes=[]\n",
    "        last_node=None\n",
    "\n",
    "        for node in graph.nodes:\n",
    "            if node.name in layer_names:\n",
    "                final_nodes.append(node)\n",
    "            if not last_node and len(final_nodes)==n:\n",
    "                last_node = node\n",
    "            if node.name == 'output':\n",
    "                out_node = node\n",
    "\n",
    "        i=0\n",
    "        nodes_to_output=[]\n",
    "        for i in range(n):\n",
    "            with graph.inserting_after(last_node):\n",
    "            # Insert a new `call_function` node calling `torch.relu`\n",
    "                new_node = graph.call_function(torch.tensor,\n",
    "                                               args=(idx[i],),\n",
    "                                              kwargs={\"dtype\":torch.int32})\n",
    "                last_node = new_node\n",
    "\n",
    "            with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.index_select,\n",
    "                                              args=(final_nodes[i], 1, last_node))\n",
    "                last_node = new_node\n",
    "\n",
    "            with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.flatten,\n",
    "                                              args=(last_node,1))\n",
    "                nodes_to_output.append(new_node)\n",
    "                last_node = new_node\n",
    "        with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.cat,\n",
    "                                              args=(nodes_to_output,1))\n",
    "        out_node.args=(new_node,)\n",
    "        graph.eliminate_dead_code()\n",
    "        graph.lint() \n",
    "        gm.recompile()\n",
    "\n",
    "        return gm\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fcl(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def get_resnet_conv_layers(self):\n",
    "        model = self.resnet\n",
    "        # we will save the conv layer weights in this list\n",
    "        model_weights =[]\n",
    "\n",
    "        #we will save the 49 conv layers in this list\n",
    "        conv_layers = []\n",
    "\n",
    "        # get all the model children as list\n",
    "        model_children = list(model.children())\n",
    "\n",
    "        #counter to keep count of the conv layers\n",
    "        counter = 0\n",
    "        #append all the conv layers and their respective wights to the list\n",
    "\n",
    "        for i in range(len(model_children)):\n",
    "\n",
    "            if type(model_children[i]) == nn.Conv2d:\n",
    "                counter+=1\n",
    "                model_weights.append(model_children[i].weight)\n",
    "                conv_layers.append(model_children[i])\n",
    "\n",
    "            elif type(model_children[i]) == nn.Sequential:\n",
    "                for j in range(len(model_children[i])):\n",
    "                    for child in model_children[i][j].children():\n",
    "                        if type(child) == nn.Conv2d:\n",
    "                            counter+=1\n",
    "                            model_weights.append(child.weight)\n",
    "                            conv_layers.append(child)\n",
    "\n",
    "        #print(f\"Total convolution layers: {counter}\")\n",
    "        #print(\"conv_layers\")\n",
    "        return (conv_layers,model_weights)\n",
    "    \n",
    "    def get_feature_map_outputs(self,image):\n",
    "        conv_layers, _ = self.get_resnet_conv_layers()\n",
    "        outputs = []\n",
    "        names = []\n",
    "\n",
    "        for layer in conv_layers[0:]:\n",
    "            image = layer(image)\n",
    "            outputs.append(image)\n",
    "            names.append(str(layer))\n",
    "            \n",
    "        #print(len(outputs))\n",
    "\n",
    "        # print feature_maps\n",
    "        #for feature_map in outputs:\n",
    "            #print(feature_map.shape)\n",
    "            \n",
    "        return outputs;   \n",
    "\n",
    "\n",
    "# testy\n",
    "transform = transforms.Compose([            #[1]\n",
    "             transforms.Resize(256),                    #[2]\n",
    "             transforms.CenterCrop(224),                #[3]\n",
    "             transforms.ToTensor(),                     #[4]\n",
    "             transforms.Normalize(                      #[5]\n",
    "             mean=[0.485, 0.456, 0.406],                #[6]\n",
    "             std=[0.229, 0.224, 0.225]                  #[7]\n",
    "             )])\n",
    "\n",
    "\n",
    "#img = Image.open(\"dog.jpg\")\n",
    "#img = Image.open('img/cat.jpg')\n",
    "#img_t = transform(img)\n",
    "#batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR10 \n",
    "import torchvision\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=19,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "trainset = images, labels\n",
    "#print(trainset)\n",
    "\n",
    "\n",
    "m = ATL(trainset, 10, 2)\n",
    "m.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False, *, maximize=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# out=m(batch_t)\n",
    "# out.size()\n",
    "\n",
    "#print(symbolic_trace(m.resnet).code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f117ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(m.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9985de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat = Image.open('img/cat.jpg')\n",
    "img_cat_t = transform(img_cat)\n",
    "batch_cat_t = torch.unsqueeze(img_cat_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75cb874d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x18624000 and 53696x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23624/3667085141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23624/2877478663.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x18624000 and 53696x10)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        \n",
    "        inputs, labels = trainset #data\n",
    "        #print(labels)\n",
    "    \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #inputs = transform(inputs)\n",
    "        \n",
    "        inputs = batch_cat_t\n",
    "        labels = torch.tensor([0])\n",
    "        \n",
    "        \n",
    "        outputs = m(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        \n",
    "        inputs, labels = trainset #data\n",
    "    \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        inputs = transform(inputs)\n",
    "        outputs = m(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947bab8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de682fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([0])\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
