{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fe63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fx as fx\n",
    "import numpy as np\n",
    "from torch.fx import symbolic_trace\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from scipy.stats import ttest_ind\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy.linalg import norm\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9dac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_few_shot_learing_data(_class,shot_number,trainloader):\n",
    "    dataiter = iter(trainloader)\n",
    "    _data = [ [] for i in range(len(_class))]\n",
    "    _data_label = [ [] for i in range(len(_class))]\n",
    "\n",
    "    while True:\n",
    "        image, label = dataiter.next()\n",
    "\n",
    "        if label in _class:\n",
    "            if len(_data[label])!=shot_number:\n",
    "                _data[label].append(image)\n",
    "                _data_label[label].append(label)\n",
    "\n",
    "        if sum([len(tab) for tab in _data]) ==   shot_number * len(_class):\n",
    "             break\n",
    "\n",
    "    out_data= []\n",
    "    out_label= [] \n",
    "\n",
    "    out_data_tensor = torch.Tensor(len(_class)*shot_number,3, 224, 224)\n",
    "    out_label_tensor= torch.Tensor(len(_class)*shot_number)\n",
    "\n",
    "    for i in range(len(_class)):\n",
    "        for j in range(shot_number):\n",
    "            out_data.append(torch.tensor(_data[i][j]).clone().detach().unsqueeze(0))        \n",
    "            out_label.append(torch.tensor(_data_label[i][j]).clone().detach()) \n",
    "\n",
    "    torch.cat(out_data , out=out_data_tensor)    \n",
    "    torch.cat(out_label , out=out_label_tensor)    \n",
    "    out_data_tensor=out_data_tensor.squeeze()\n",
    "    out_label_tensor = out_label_tensor.type(torch.long)\n",
    "    trainset_few_shot = out_data_tensor.squeeze(),out_label_tensor.squeeze()\n",
    "    return trainset_few_shot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a380f1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\AppData\\Local\\Temp/ipykernel_5460/3794376688.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out_data.append(torch.tensor(_data[i][j]).clone().detach().unsqueeze(0))\n",
      "C:\\Users\\barto\\AppData\\Local\\Temp/ipykernel_5460/3794376688.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out_label.append(torch.tensor(_data_label[i][j]).clone().detach())\n"
     ]
    }
   ],
   "source": [
    "np.random.seed = 123\n",
    "torch.manual_seed(0)\n",
    "\n",
    "transform = transforms.Compose([                        #[1]\n",
    "             transforms.Resize(256),                    #[2]\n",
    "             transforms.CenterCrop(224),                #[3]\n",
    "             transforms.ToTensor(),                     #[4]\n",
    "             transforms.Normalize(                      #[5]\n",
    "             mean=[0.485, 0.456, 0.406],                #[6]\n",
    "             std=[0.229, 0.224, 0.225]                  #[7]\n",
    "             )])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "_class = [0,1,2,3,4]\n",
    "shot_number = 5\n",
    "\n",
    "trainset_few_shot = get_few_shot_learing_data(_class,shot_number,trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a38d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23, 56, 35, 13, 42, 36, 33, 29, 32, 59, 19, 1, 22, 47, 12, 37, 4, 10, 29, 63, 19, 10, 22, 40, 51, 37, 57, 24, 33, 21, 35, 14, 0, 49, 22, 50, 2, 61, 37, 6, 36, 54, 56, 32, 13, 24, 46, 55, 15, 48], [88, 496, 21, 161, 261, 226, 434, 428, 130, 239, 187, 261, 117, 162, 157, 301, 185, 114, 306, 257, 328, 23, 416, 330, 84, 269, 69, 204, 18, 212, 385, 48, 488, 421, 427, 412, 74, 122, 457, 462, 328, 397, 461, 167, 323, 330, 60, 331, 172, 190], [163, 421, 181, 82, 51, 161, 351, 110, 94, 218, 76, 47, 73, 348, 234, 477, 301, 499, 369, 12, 76, 471, 117, 91, 481, 60, 98, 27, 478, 286, 220, 85, 188, 105, 429, 310, 282, 307, 499, 12, 218, 91, 480, 286, 421, 181, 414, 509, 394, 371]]\n",
      "632100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ATL(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Module(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): Module(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Module(\n",
       "      (0): Module(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Module(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (fcl): Linear(in_features=632100, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class ATL(nn.Module):\n",
    "    def __init__(self, train, Nclasses, Nlayer=3, Pmax=0.4):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        layers = self.get_layers(train,Nlayer)\n",
    "        fm_indicies, resnet_out_size = self.get_featuremaps_idicies(train,layers) \n",
    "        self.resnet = self._transform(self.resnet, Nlayer, layers, fm_indicies)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fcl = nn.Linear(resnet_out_size, Nclasses)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "            \n",
    "    def get_layers(self, train,number_of_layers):\n",
    "        images, labels = train\n",
    "        conv_layers,model_weights = self.get_resnet_conv_layers()\n",
    "        feature_map_outputs_for_images = [self.get_feature_map_outputs(image) for image in images]\n",
    "        labels_set = set(np.asarray(labels))\n",
    "        \n",
    "        R_scores_for_layers = []\n",
    "\n",
    "        for conv_ind in range(len(conv_layers)):\n",
    "            \n",
    "            centroids_for_class =[]\n",
    "            LAV_vec = []             \n",
    "                                \n",
    "            for image_ind,image in enumerate(images):\n",
    "                LAV_vec_image = []\n",
    "                out_fm = feature_map_outputs_for_images[image_ind]\n",
    "                for fm_ind in range(len(model_weights[conv_ind])):\n",
    "                    LAV_vec_image.append(self.LAV(out_fm[conv_ind][fm_ind])) ##lav_vec jest vectorem przyjmującym lav dla każdego obrazka\n",
    "                LAV_vec.append(LAV_vec_image)\n",
    "            \n",
    "              \n",
    "                #iterujemy po klasach w danych\n",
    "            for class_id, _class in enumerate(labels_set):\n",
    "                    LAV_vec_curent_class = []\n",
    "                    for i,fm in enumerate(LAV_vec):\n",
    "                        if labels[i]==_class:\n",
    "                            LAV_vec_curent_class.append(fm)\n",
    "                    \n",
    "                    n = len(LAV_vec_curent_class)\n",
    "                    suma = np.asarray([0.0]*len(LAV_vec_curent_class[0]))\n",
    "                    for k in range(n):\n",
    "                        norm_l2 = norm(LAV_vec_curent_class[k])\n",
    "                        nmn = np.asarray(LAV_vec_curent_class[k])/norm_l2\n",
    "                        suma += nmn\n",
    "                    centroid = 1/n * suma\n",
    "                    centroids_for_class.append(centroid)\n",
    "            \n",
    "            #R-score\n",
    "            r_val = []\n",
    "            for a in range(len(centroids_for_class)):\n",
    "                for b in range(len(centroids_for_class)):\n",
    "                    if a !=b:\n",
    "                        rrrr = np.linalg.norm(centroids_for_class[a]-centroids_for_class[b])\n",
    "                        r_val.append(rrrr)\n",
    "            R = min(r_val)\n",
    "            R_scores_for_layers.append(R)\n",
    "\n",
    "        # choosing the best n layers\n",
    "        lst = pd.Series(R_scores_for_layers)\n",
    "        i = lst.nlargest(number_of_layers)        \n",
    "        return i.index.values.tolist() # najlepiej indeksy warstw konwolucyjnych \n",
    "        \n",
    "    def get_featuremaps_idicies(self, train, layers, N_feature  = 10):\n",
    "        \n",
    "        dim0=[112]\n",
    "        dim1=[56]*9\n",
    "        dim2=[28]*12\n",
    "        dim3=[14]*19\n",
    "        dim4=[7]*9\n",
    "        fm_dim = np.concatenate((dim0,dim1,dim2,dim3,dim4))        \n",
    "        images, labels = train\n",
    "        #print(labels)\n",
    "        labels_set = set(np.asarray(labels))                \n",
    "        conv_layers,model_weights = self.get_resnet_conv_layers()    \n",
    "        choose_fm = []\n",
    "        choose_fm_output_len=0        \n",
    "        feature_map_outputs_for_images = [self.get_feature_map_outputs(image) for image in images]\n",
    "                \n",
    "        # iteruje po warstwach konwolucyjnuch \n",
    "        for conv_ind in layers:\n",
    "            choose_fm_curent_conv_layer = []            \n",
    "            p_score_for_classs_and_maps  = [{} for i in range(len(labels_set))]\n",
    "            \n",
    "            # iteruje po mapach             \n",
    "            for fm_ind in range(len(model_weights[conv_ind])):                \n",
    "                LAV_vec = []\n",
    "                    \n",
    "                for image_ind,image in enumerate(images):\n",
    "                    out_fm = feature_map_outputs_for_images[image_ind]\n",
    "                    LAV_vec.append(self.LAV(out_fm[conv_ind][fm_ind]))\n",
    "                 \n",
    "                #iterujemy po klasach w danych\n",
    "                for class_id, _class in enumerate(labels_set):\n",
    "                    LAV_vec_curent_class = []\n",
    "                    LAV_vec_other_class = []\n",
    "                    for i,fm in enumerate(LAV_vec):\n",
    "                        if labels[i]==_class:\n",
    "                            LAV_vec_curent_class.append(fm)\n",
    "                        else:     \n",
    "                            LAV_vec_other_class.append(fm)\n",
    "                    \n",
    "                    # zwraca nan przy LAV_vec_current_class długości 1 !!\n",
    "                    # czyli wtedy gdy z jakiejś klasy była tylko jedna obserwacja\n",
    "                    # przy treningu nie będzie takiej sytucji\n",
    "                    t_stat, p = ttest_ind(LAV_vec_curent_class, LAV_vec_other_class)\n",
    "                    \n",
    "                    if(math.isnan(p)): \n",
    "                        print(\"error: klasa o jednym elemencie\")\n",
    "                        p=1\n",
    "                    \n",
    "                    _dict = p_score_for_classs_and_maps[class_id]\n",
    "                    _dict[p] = fm_ind\n",
    "            \n",
    "            for class_id, p_scores_and_map_indexes in enumerate(p_score_for_classs_and_maps): \n",
    "                \n",
    "                #wybranie N_feature, \"najlepszych\" map dla każdej klasy\"\n",
    "                p_scores = list(p_scores_and_map_indexes.keys())                \n",
    "                sort_p_scores =  np.sort(p_scores)\n",
    "                low_p_scores = sort_p_scores[:N_feature]\n",
    "                \n",
    "                for p_score in low_p_scores:\n",
    "                    fm_ind = p_scores_and_map_indexes.get(p_score)\n",
    "                    choose_fm_curent_conv_layer.append(fm_ind)\n",
    "                    choose_fm_output_len += fm_dim[conv_ind]**2\n",
    "                                        \n",
    "            choose_fm.append(choose_fm_curent_conv_layer)\n",
    "        \n",
    "        print (choose_fm)\n",
    "        print (choose_fm_output_len)\n",
    "        \n",
    "        # Musi zwracać obiekt który ma N iterowalnych rzeczy, z których każda ma ileś indeksów feature map. \n",
    "        # W sumie ilość indeksów musi być równa ilości klas * Nfeature z 2.3 w artykule\n",
    "        #return [[1],[1]], 1568\n",
    "        \n",
    "        return choose_fm, choose_fm_output_len \n",
    "    \n",
    "    \n",
    "    def LAV(self,featureMap):\n",
    "        return featureMap.max().detach().numpy().item(0)\n",
    "    \n",
    "    def _transform(self, m: torch.nn.Module, n, layers, idx) -> torch.nn.Module:\n",
    "        gm : torch.fx.GraphModule = torch.fx.symbolic_trace(m)\n",
    "        graph=gm.graph\n",
    "        blocks_in_layers = [1,3,4,6,3]\n",
    "        idx_to_layer_name = ['conv1'] +[f\"layer{i}_{j}_conv{k}\" for i in range(1,5) for j in range(blocks_in_layers[i]) for k in range(1,4)]\n",
    "        layer_names = [idx_to_layer_name[idx] for idx in layers]\n",
    "        final_nodes=[]\n",
    "        last_node=None\n",
    "\n",
    "        for node in graph.nodes:\n",
    "            if node.name in layer_names:\n",
    "                final_nodes.append(node)\n",
    "            if not last_node and len(final_nodes)==n:\n",
    "                last_node = node\n",
    "            if node.name == 'output':\n",
    "                out_node = node\n",
    "\n",
    "        i=0\n",
    "        nodes_to_output=[]\n",
    "        for i in range(n):\n",
    "            with graph.inserting_after(last_node):\n",
    "            # Insert a new `call_function` node calling `torch.relu`\n",
    "                new_node = graph.call_function(torch.tensor,\n",
    "                                               args=(idx[i],),\n",
    "                                              kwargs={\"dtype\":torch.int32})\n",
    "                last_node = new_node\n",
    "\n",
    "            with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.index_select,\n",
    "                                              args=(final_nodes[i], 1, last_node))\n",
    "                last_node = new_node\n",
    "\n",
    "            with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.flatten,\n",
    "                                              args=(last_node,1))\n",
    "                nodes_to_output.append(new_node)\n",
    "                last_node = new_node\n",
    "        with graph.inserting_after(last_node):\n",
    "                new_node = graph.call_function(torch.cat,\n",
    "                                              args=(nodes_to_output,1))\n",
    "        out_node.args=(new_node,)\n",
    "        graph.eliminate_dead_code()\n",
    "        graph.lint() \n",
    "        gm.recompile()\n",
    "\n",
    "        return gm\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fcl(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def get_resnet_conv_layers(self):\n",
    "        model = self.resnet\n",
    "        # we will save the conv layer weights in this list\n",
    "        model_weights =[]\n",
    "\n",
    "        #we will save the 49 conv layers in this list\n",
    "        conv_layers = []\n",
    "\n",
    "        # get all the model children as list\n",
    "        model_children = list(model.children())\n",
    "\n",
    "        #counter to keep count of the conv layers\n",
    "        counter = 0\n",
    "        #append all the conv layers and their respective wights to the list\n",
    "\n",
    "        for i in range(len(model_children)):\n",
    "\n",
    "            if type(model_children[i]) == nn.Conv2d:\n",
    "                counter+=1\n",
    "                model_weights.append(model_children[i].weight)\n",
    "                conv_layers.append(model_children[i])\n",
    "\n",
    "            elif type(model_children[i]) == nn.Sequential:\n",
    "                for j in range(len(model_children[i])):\n",
    "                    for child in model_children[i][j].children():\n",
    "                        if type(child) == nn.Conv2d:\n",
    "                            counter+=1\n",
    "                            model_weights.append(child.weight)\n",
    "                            conv_layers.append(child)\n",
    "\n",
    "        #print(f\"Total convolution layers: {counter}\")\n",
    "        #print(\"conv_layers\")\n",
    "        return (conv_layers,model_weights)\n",
    "    \n",
    "    def get_feature_map_outputs(self,image):\n",
    "        conv_layers, _ = self.get_resnet_conv_layers()\n",
    "        outputs = []\n",
    "        names = []\n",
    "\n",
    "        for layer in conv_layers[0:]:\n",
    "            image = layer(image)\n",
    "            outputs.append(image)\n",
    "            names.append(str(layer))\n",
    "            \n",
    "        #print(len(outputs))\n",
    "\n",
    "        # print feature_maps\n",
    "        #for feature_map in outputs:\n",
    "            #print(feature_map.shape)\n",
    "            \n",
    "        return outputs;   \n",
    "\n",
    "\n",
    "\n",
    "# CIFAR100 \n",
    "\n",
    "# transform = transforms.Compose([                        #[1]\n",
    "#              transforms.Resize(256),                    #[2]\n",
    "#              transforms.CenterCrop(224),                #[3]\n",
    "#              transforms.ToTensor(),                     #[4]\n",
    "#              transforms.Normalize(                      #[5]\n",
    "#              mean=[0.485, 0.456, 0.406],                #[6]\n",
    "#              std=[0.229, 0.224, 0.225]                  #[7]\n",
    "#              )])\n",
    "\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# # get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "# trainset = images, labels\n",
    "# #print(trainset)\n",
    "\n",
    "# print(images)\n",
    "# print(labels)\n",
    "\n",
    "\n",
    "\n",
    "m = ATL(trainset_few_shot, 10, 3)\n",
    "m.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c2ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(m.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(m.parameters(),lr=0.01)\n",
    "scheduler = lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffd3585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.093\n",
      "[2] loss: 0.070\n",
      "[3] loss: 0.070\n",
      "[4] loss: 0.070\n",
      "[5] loss: 0.070\n",
      "[6] loss: 0.070\n",
      "[7] loss: 0.070\n",
      "[8] loss: 0.070\n",
      "[9] loss: 0.070\n",
      "[10] loss: 0.070\n",
      "[11] loss: 0.070\n",
      "[12] loss: 0.070\n",
      "[13] loss: 0.070\n",
      "[14] loss: 0.070\n",
      "[15] loss: 0.070\n",
      "[16] loss: 0.070\n",
      "[17] loss: 0.070\n",
      "[18] loss: 0.070\n",
      "[19] loss: 0.070\n",
      "[20] loss: 0.070\n",
      "[21] loss: 0.070\n",
      "[22] loss: 0.070\n",
      "[23] loss: 0.070\n",
      "[24] loss: 0.070\n",
      "[25] loss: 0.070\n",
      "[26] loss: 0.070\n",
      "[27] loss: 0.070\n",
      "[28] loss: 0.070\n",
      "[29] loss: 0.070\n",
      "[30] loss: 0.070\n",
      "[31] loss: 0.070\n",
      "[32] loss: 0.070\n",
      "[33] loss: 0.070\n",
      "[34] loss: 0.070\n",
      "[35] loss: 0.070\n",
      "[36] loss: 0.070\n",
      "[37] loss: 0.070\n",
      "[38] loss: 0.070\n",
      "[39] loss: 0.070\n",
      "[40] loss: 0.070\n",
      "[41] loss: 0.070\n",
      "[42] loss: 0.070\n",
      "[43] loss: 0.070\n",
      "[44] loss: 0.070\n",
      "[45] loss: 0.070\n",
      "[46] loss: 0.070\n",
      "[47] loss: 0.070\n",
      "[48] loss: 0.070\n",
      "[49] loss: 0.070\n",
      "[50] loss: 0.070\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    \n",
    "\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    # get the inputs\n",
    "    inputs, labels = trainset_few_shot #data\n",
    "\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    outputs = m(inputs)\n",
    "    #print(len(labels))\n",
    "    #print(len(outputs))\n",
    "    \n",
    "\n",
    "        \n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    print('[%d] loss: %.3f' %\n",
    "        (epoch + 1, running_loss / 25))\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    \n",
    "#     print('[%d] loss: %.3f' %\n",
    "#         (epoch + 1, running_loss / 25))\n",
    "        \n",
    "    if epoch % 20 == 0:\n",
    "        pass\n",
    "        #scheduler.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
